#' Pipeline for Single Cell Data
#'
#' @md
#'
#' @description
#' Semi-supervised isoform detection and annotation for long read data.
#' This variant is for single cell data. By default, this pipeline demultiplexes input
#' fastq data (\code{match_cell_barcode = TRUE}). Specific parameters relating to
#' analysis can be changed either through function arguments, or through a
#' configuration JSON file.
#'
#' @details
#' By default FLAMES use minimap2 for read alignment. After the genome alignment step (\code{do_genome_align}), FLAMES summarizes the alignment for each read by grouping reads
#' with similar splice junctions to get a raw isoform annotation (\code{do_isoform_id}). The raw isoform
#' annotation is compared against the reference annotation to correct potential splice site
#' and transcript start/end errors. Transcripts that have similar splice junctions
#' and transcript start/end to the reference transcript are merged with the
#' reference. This process will also collapse isoforms that are likely to be truncated
#' transcripts. If \code{isoform_id_bambu} is set to \code{TRUE}, \code{bambu::bambu} will be used to generate the updated annotations.
#' Next is the read realignment step (\code{do_read_realign}), where the sequence of each transcript from the update annotation is extracted, and
#' the reads are realigned to this updated \code{transcript_assembly.fa} by minimap2. The
#' transcripts with only a few full-length aligned reads are discarded.
#' The reads are assigned to transcripts based on both alignment score, fractions of
#' reads aligned and transcript coverage. Reads that cannot be uniquely assigned to
#' transcripts or have low transcript coverage are discarded. The UMI transcript
#' count matrix is generated by collapsing the reads with the same UMI in a similar
#' way to what is done for short-read scRNA-seq data, but allowing for an edit distance
#' of up to 2 by default. Most of the parameters, such as the minimal distance to splice site and minimal percentage of transcript coverage
#' can be modified by the JSON configuration file (\code{config_file}).
#'
#' @param annotation The file path to the annotation file in GFF3 format
#' @param fastq The file path to input fastq file
#' @param genome_bam Optional file path to a bam file to use instead of fastq file (skips initial alignment step)
#' @param outdir The path to directory to store all output files.
#' @param genome_fa The file path to genome fasta file.
#' @param minimap2 Path to minimap2, if it is not in PATH. Only required if either or both of
#' \code{do_genome_align} and \code{do_read_realign} are \code{TRUE}.
#' @param config_file File path to the JSON configuration file. If specified, \code{config_file} overrides
#' all configuration parameters
#' @param barcodes_file The file path to the reference csv used for demultiplexing in flexiplex. If not specified, the 
#'                           demultiplexing will be performed using BLAZE. Default is \code{NULL}.
#' @param expect_cell_number Expected number of cells for identifying the barcode list in BLAZE. 
#'                           This could be just a rough estimate. E.g., the targeted number of cells.
#'                           Required if the \code{do_barcode_demultiplex} are \code{TRUE} in the the JSON configuration file
#'                           and \code{barcodes_file} is not specified. Default is \code{NULL}.
#' 
#' @return if \code{do_transcript_quantification} set to true, \code{sc_long_pipeline} returns a \code{SingleCellExperiment} object, containing a count
#' matrix as an assay, gene annotations under metadata, as well as a list of the other
#' output files generated by the pipeline. The pipeline also outputs a number of output
#' files into the given \code{outdir} directory. These output files generated by the pipeline are:
#' \itemize{
#'  \item{transcript_count.csv.gz}{ - a transcript count matrix (also contained in the SingleCellExperiment)}
#'  \item{isoform_annotated.filtered.gff3}{ - isoforms in gff3 format (also contained in the SingleCellExperiment)}
#'  \item{transcript_assembly.fa}{ - transcript sequence from the isoforms}
#'  \item{align2genome.bam}{ - sorted BAM file with reads aligned to genome}
#'  \item{realign2transcript.bam}{ - sorted realigned BAM file using the transcript_assembly.fa as reference}
#'  \item{tss_tes.bedgraph}{ - TSS TES enrichment for all reads (for QC)}
#' }
#' if \code{do_transcript_quantification} set to false, nothing will be returned
#'
#' @details The default parameters can be changed either through the function
#' arguments are through the configuration JSON file \code{config_file}. the \code{pipeline_parameters}
#' section specifies which steps are to be executed in the pipeline - by default, all
#' steps are executed. The \code{isoform_parameters} section affects isoform detection - key
#' parameters include:
#' \itemize{
#'  \item{\code{Min_sup_cnt}}{ which causes transcripts with less reads aligned than
#' it's value to be discarded}
#'  \item{\code{MAX_TS_DIST}}{ which merges transcripts with the same intron
#' chain and TSS/TES distace less than \code{MAX_TS_DIST}}
#'  \item{\code{strand_specific}}{ which specifies if reads are in the same strand as the mRNA (1),
#' or the reverse complemented (-1) or not strand specific (0), which results in
#' strand information being based on reference annotation.}
#' }
#'
#' @seealso
#' [bulk_long_pipeline()] for bulk long data,
#' [SingleCellExperiment()] for how data is outputted
#'
#' @importFrom dplyr group_by summarise_at slice_max filter
#' @importFrom magrittr "%>%"
#' @importFrom SingleCellExperiment SingleCellExperiment reducedDimNames logcounts
#' @importFrom SummarizedExperiment rowData colData rowData<- colData<- rowRanges rowRanges<-
#' @importFrom BiocGenerics cbind colnames rownames start end
#' @importFrom utils read.csv read.table
#' @importFrom GenomeInfoDb seqlengths
#'
#' @examples
#' outdir <- tempfile()
#' dir.create(outdir)
#' bc_allow <- file.path(outdir, "bc_allow.tsv")
#' genome_fa <- file.path(outdir, "rps24.fa")
#' R.utils::gunzip(filename = system.file("extdata/bc_allow.tsv.gz", package = "FLAMES"), destname = bc_allow, remove = FALSE)
#' R.utils::gunzip(filename = system.file("extdata/rps24.fa.gz", package = "FLAMES"), destname = genome_fa, remove = FALSE)
#'
#' if (all(is.character(sys_which(c("minimap2", "k8"))))) {
#'     sce <- FLAMES::sc_long_pipeline(
#'         genome_fa = genome_fa,
#'         fastq = system.file("extdata/fastq", package = "FLAMES"),
#'         annotation = system.file("extdata/rps24.gtf.gz", package = "FLAMES"),
#'         outdir = outdir,
#'         barcodes_file = bc_allow
#'     )
#' }
#' @export
sc_long_pipeline <-
    function(annotation,
             fastq,
             genome_bam = NULL,
             outdir,
             genome_fa,
             minimap2 = NULL,
             k8 = NULL,
             barcodes_file = NULL,
             expect_cell_number = NULL,
             config_file = NULL
             ) {
        checked_args <- check_arguments(
            annotation,
            fastq,
            genome_bam,
            outdir,
            genome_fa,
            config_file
        )
        cat(format(Sys.time(), "%X %a %b %d %Y"), "Start running\n")
        config <- checked_args$config

        infq <- NULL
        if (config$pipeline_parameters$do_barcode_demultiplex) {

            if (file.exists(file.path(outdir, "matched_reads.fastq"))) {
                stop(paste0("The demultiplexing output file matched_reads.fastq already exists in the output directory.",
                " If you want to run the demultiplexing step again, please remove the file first,  ",
                "otherwise please set `do_barcode_demultiplex = false` in the JSON configuration file."))
            }

            if (is.null(barcodes_file)){
                # run blaze
                cat("Running BLAZE to generate barcode list from long reads...\n")
                if (is.null(expect_cell_number)){
                    stop("'expect_cell_number' is required to run BLAZE for barcode identification. Please specify it.")
                }
                blaze(expect_cell_number, fastq, 
                     'output-prefix' = paste0(outdir, '/'),
                     'output-fastq' = 'matched_reads.fastq',
                    'threads' = config$pipeline_parameters$threads,
                    'max-edit-distance' = config$barcode_parameters$max_bc_editdistance,
                    'overwrite' = TRUE)
                    
                infq <- file.path(outdir, "matched_reads.fastq")
            } else {
                # run flexiplex
                cat(format(Sys.time(), "%X %a %b %d %Y"), "Demultiplexing using flexiplex...\n")
                if (!file.exists(barcodes_file)) {
                    stop("The brcodes_file ",barcodes_file, " doesn't exists. Please check the path.",
                    " If you do not have a barcode file, please set `brcodes_file = NULL` to run BLAZE.")
                }
                cat("Matching cell barcodes...\n")
                infq <- file.path(outdir, "matched_reads.fastq")
                bc_stat <- file.path(outdir, "matched_barcode_stat")
                find_barcode(
                    fastq = fastq,
                    barcodes_file = barcodes_file,
                    stats_out = bc_stat,
                    reads_out = infq,
                    pattern = setNames(as.character(config$barcode_parameters$pattern), 
                                    names(config$barcode_parameters$pattern)),
                    TSO_seq = config$barcode_parameters$TSO,
                    TSO_prime = config$barcode_parameters$TSO_prime,
                    max_bc_editdistance = config$barcode_parameters$max_bc_editdistance, 
                    max_flank_editdistance = config$barcode_parameters$max_flank_editdistance,
                full_length_only = config$barcode_parameters$full_length_only,
                    threads = config$pipeline_parameters$threads
                )
            } 
            cat(format(Sys.time(), "%X %a %b %d %Y"), "Demultiplex done\n")
        } else {
            infq <- fastq
            cat("Skipping Demultiplexing step...\n")
            cat("Please make sure the `",infq,"`` is the the demultiplexing output from previous FLAEMS call.\n")
        } # requesting to not match barcodes implies `fastq` has already been run through the
        # function in a previous FLAMES call
        cat("Running FLAMES pipeline...\n")

        using_bam <- FALSE
        if (!is.null(genome_bam)) {
            if (!file.exists(paste0(genome_bam, ".bai")) && !file.exists(paste0(genome_bam, ".csi"))) {
                stop("Please make sure the BAM file is indexed")
            }
            using_bam <- TRUE
            config$pipeline_parameters$do_genome_alignment <- FALSE
        }

        cat("#### Input parameters:\n")
        cat(jsonlite::toJSON(config, pretty = TRUE), "\n")
        cat("gene annotation:", annotation, "\n")
        cat("genome fasta:", genome_fa, "\n")
        if (using_bam) {
            cat("input bam:", genome_bam, "\n")
        } else {
            genome_bam <- file.path(outdir, "align2genome.bam")
        }
        cat("input fastq:", infq, "\n")
        cat("output directory:", outdir, "\n")
        cat("minimap2 path:", minimap2, "\n")
        cat("k8 path:", k8, "\n")

        # align reads to genome
        # if (!using_bam && config$pipeline_parameters$do_genome_alignment) {
        if (config$pipeline_parameters$do_genome_alignment) {
            cat("#### Aligning reads to genome using minimap2\n")
            minimap2_align(
                config,
                genome_fa,
                infq,
                annotation,
                outdir,
                minimap2,
                k8,
                prefix = NULL,
                threads = config$pipeline_parameters$threads
            )
        } else {
            cat("#### Skip aligning reads to genome\n")
        }

        # gene quantification and UMI deduplication
        
        if (config$pipeline_parameters$do_gene_quantification) {
            cat(format(Sys.time(), "%X %a %b %d %Y"), "Start gene quantification and UMI deduplication\n")
            
            quantify_gene(annotation, outdir, config$pipeline_parameters$threads,
                        pipeline = "sc_single_sample")
            
            cat(format(Sys.time(), "%X %a %b %d %Y"), "Gene quantification and UMI deduplication done!\n")
        }else {
            cat("#### Skip gene quantification and UMI deduplication\n")
        }
        

        # find isofroms
        
        if (config$pipeline_parameters$do_isoform_identification) {
            cat(format(Sys.time(), "%X %a %b %d %Y"), "Start isoform identificaiton\n")
            find_isoform(annotation, genome_fa, genome_bam, outdir, config)
            cat(format(Sys.time(), "%X %a %b %d %Y"), "Isoform identificaiton done\n")
        } else {
            cat("#### Skip isoform identificaiton\n")
            # create transcript_assembly.fa using GTF if not exists
            if (!file.exists(file.path(outdir, "transcript_assembly.fa"))) {
                cat("#### Generating transcript_assembly.fa from annotation\n")
                annotation_to_fasta(annotation, genome_fa, outdir)
            } 
        }
       
        
        # realign to transcript
        if (config$pipeline_parameters$do_read_realignment) {
            cat("#### Realigning deduplicated reads to transcript using minimap2\n")
            if (config$pipeline_parameters$do_gene_quantification) {
                infq_realign <- file.path(outdir, "matched_reads_dedup.fastq")
            } else {
                infq_realign <- infq
            }
            



            # minimap2_realign looks for the transcript_assembly.fa file in the outdir
            minimap2_realign(config, infq_realign, outdir, minimap2, prefix = NULL, 
                             threads = config$pipeline_parameters$threads)
        } else {
            cat("#### Skip read realignment\n")
        }

        # transcript quantification
        if (config$pipeline_parameters$do_transcript_quantification) {
            cat("#### Generating transcript count matrix\n")
            quantify_transcript(annotation = annotation, 
                                outdir = outdir, 
                                pipeline = "sc_single_sample",
                                config = config)

            out_files <- list(
                "annotation" = annotation,
                "genome_fa" = genome_fa,
                "counts" = file.path(outdir, "transcript_count.csv.gz"),
                "isoform_annotated" = file.path(outdir, "isoform_annotated.filtered.gff3"),
                "transcript_assembly" = file.path(outdir, "transcript_assembly.fa"),
                "align_bam" = genome_bam,
                "realign2transcript" = file.path(outdir, "realign2transcript.bam"),
                "tss_tes" = file.path(outdir, "tss_tes.bedgraph"),
                "outdir" = outdir
            )

            load_genome_anno <- rtracklayer::import(annotation, feature.type = c("exon", "utr"))
            sce <- generate_sc_singlecell(out_files, load_genome_anno = load_genome_anno)

            return(sce)
        } else {
            cat("#### Skip transcript quantification\n")
        }
    }

#' @importFrom utils read.csv
#' @importFrom GenomicRanges GRangesList GRanges
generate_sc_sce <- function(out_files, load_genome_anno = NULL, create_function) {
    # this method requires testing using single cell data
    mdata <- list(
        "OutputFiles" = out_files
    )

    transcript_count <- read.csv(out_files$counts, stringsAsFactors = FALSE)
    if ("fsm_annotation" %in% names(out_files)) {
        isoform_FSM_annotation <- read.csv(out_files$fsm_annotation, stringsAsFactors = FALSE)
    } else {
        isoform_FSM_annotation <- read.csv(file.path(out_files$outdir, "isoform_FSM_annotation.csv"), stringsAsFactors = FALSE)
    }
    transcript_count <- transcript_count[transcript_count$transcript_id %in% isoform_FSM_annotation$transcript_id, ]

    isoform_FSM_annotation <- isoform_FSM_annotation[match(transcript_count$transcript_id, isoform_FSM_annotation$transcript_id), ]
    # transcript_count <- transcript_count[match(isoform_FSM_annotation$transcript_id, transcript_count$transcript_id), ]
    transcript_count$FSM_match <- isoform_FSM_annotation$FSM_match
    if (!all(transcript_count$transcript_id %in% isoform_FSM_annotation$transcript_id)) {
        message("Some transcript_ids are not recorded in isoform_FSM_annotation.csv")
        transcript_count$FSM_match[is.na(transcript_count$FSM_match)] <- transcript_count$transcript_id[is.na(transcript_count$FSM_match)]
    }

    cell_bcs <- colnames(transcript_count)[!(colnames(transcript_count) %in% c("transcript_id", "gene_id", "FSM_match"))]
    tr_anno <- transcript_count[, c("transcript_id", "gene_id", "FSM_match")]

    # sum transcript (FSM) counts
    mer_tmp <- transcript_count %>%
        group_by(FSM_match) %>%
        summarise_at(cell_bcs, sum)

    # Create long read SCE
    tr_anno <- tr_anno[match(mer_tmp$FSM_match, tr_anno$FSM_match), ]
    tr_sce <- create_function(
        assays = list(counts = as.matrix(mer_tmp[, -1])),
        metadata = mdata
    )
    # rownames(tr_sce) <- mer_tmp$FSM_match

    isoform_gff <- get_GRangesList(out_files$isoform_annotated)
    missing_tr <- !(tr_anno$transcript_id %in% names(isoform_gff))

    rowRanges(tr_sce) <- rep(GRangesList(GRanges(seqnames = NULL, ranges = NULL, strand = NULL, seqinfo = NULL, seqlengths = NULL)), dim(tr_sce)[1])

    if (!is.null(load_genome_anno)) {
        genome_anno <- S4Vectors::split(load_genome_anno, load_genome_anno$transcript_id)
        add_from_genome_anno <- (missing_tr & (tr_anno$transcript_id %in% names(genome_anno)))
        rowRanges(tr_sce[add_from_genome_anno, ]) <- genome_anno[tr_anno[add_from_genome_anno, "transcript_id"]]
        if (!all((!missing_tr) | tr_anno[, "transcript_id"] %in% names(genome_anno))) {
            message("Warning: some transcript_id could not be found in annotation file\n")
        }
    } else if (any(missing_tr)) {
        message("Warning: some transcript_id could not be found in annotation file\n")
    }

    rowRanges(tr_sce[!missing_tr, ]) <- isoform_gff[tr_anno[!missing_tr, "transcript_id"]]


    rowData(tr_sce) <- DataFrame(tr_anno)
    rownames(tr_sce) <- tr_anno$FSM_match
    # return the created singlecellexperiment
    return(tr_sce)
}

generate_sc_singlecell <- function(out_files, load_genome_anno = NULL) {
    return(generate_sc_sce(out_files = out_files, load_genome_anno = load_genome_anno, create_function = SingleCellExperiment::SingleCellExperiment))
}

generate_bulk_summarized <- function(out_files, load_genome_anno = NULL) {
    return(generate_sc_sce(out_files = out_files, load_genome_anno = load_genome_anno, create_function = SummarizedExperiment::SummarizedExperiment))
}


#' Create \code{SingleCellExperiment} object from \code{FLAMES} output folder
#' @param outdir The folder containing \code{FLAMES} output files
#' @param annotation (Optional) the annotation file that was used to produce the output files
#' @return a list of \code{SingleCellExperiment} objects if multiple transcript matrices were
#' found in the output folder, or a \code{SingleCellExperiment} object if only one were found
#' @export
#' @examples
#' outdir <- tempfile()
#' dir.create(outdir)
#' bc_allow <- file.path(outdir, "bc_allow.tsv")
#' genome_fa <- file.path(outdir, "rps24.fa")
#' R.utils::gunzip(filename = system.file("extdata/bc_allow.tsv.gz", package = "FLAMES"), destname = bc_allow, remove = FALSE)
#' R.utils::gunzip(filename = system.file("extdata/rps24.fa.gz", package = "FLAMES"), destname = genome_fa, remove = FALSE)
#' annotation <- system.file("extdata/rps24.gtf.gz", package = "FLAMES")
#'
#' if (all(is.character(sys_which(c("minimap2", "k8"))))) {
#'     sce <- FLAMES::sc_long_pipeline(
#'         genome_fa = genome_fa,
#'         fastq = system.file("extdata/fastq", package = "FLAMES"),
#'         annotation = annotation,
#'         outdir = outdir,
#'         barcodes_file = bc_allow
#'     )
#'     sce_2 <- create_sce_from_dir(outdir, annotation)
#' }
create_sce_from_dir <- function(outdir, annotation) {
    samples <- list.files(outdir)[grepl("_?transcript_count.csv.gz", list.files(outdir))]
    if (length(samples) == 0) {
        stop("Cannot find transcript_count.csv.gz file in", outdir)
    }
    sce_list <- list()
    if (file.exists(file.path(outdir, "isoform_annotated.gtf"))) {
      isoform_annotated <- file.path(outdir, "isoform_annotated.gtf")
    } else if (file.exists(file.path(outdir, "isoform_annotated.gff3"))) {
      isoform_annotated <- file.path(outdir, "isoform_annotated.gff3")
    } else {
      stop("Missing isoform_annotated.gff3/gtf file")
    }

    for (i in 1:length(samples)) {
        out_files <- list(
            counts = file.path(outdir, samples[i]),
            isoform_annotated = isoform_annotated,
            outdir = outdir,
            transcript_assembly = file.path(outdir, "transcript_assembly.fa")
        )
        if (!missing("annotation") && !is.null(annotation)) {
            out_files[["annotation"]] <- annotation
            load_genome_anno <- rtracklayer::import(annotation, feature.type = c("exon", "utr"))
            sce_list[[samples[i]]] <- generate_sc_singlecell(out_files, load_genome_anno = load_genome_anno)
        } else {
            sce_list[[samples[i]]] <- generate_sc_singlecell(out_files)
        }
    }
    if (length(samples) == 1) {
        return(sce_list[[1]])
    }
    return(sce_list)
}

#' Create \code{SummarizedExperiment} object from \code{FLAMES} output folder
#' @param outdir The folder containing \code{FLAMES} output files
#' @param annotation (Optional) the annotation file that was used to produce the output files
#' @return a \code{SummarizedExperiment} object
#' @example inst/examples/pipeline_example.R
#' @export
create_se_from_dir <- function(outdir, annotation) {
    if (file.exists(file.path(outdir, "isoform_annotated.gtf"))) {
      isoform_annotated <- file.path(outdir, "isoform_annotated.gtf")
    } else if (file.exists(file.path(outdir, "isoform_annotated.gff3"))) {
      isoform_annotated <- file.path(outdir, "isoform_annotated.gff3")
    } else {
      stop("Missing isoform_annotated.gff3/gtf file")
    }
    out_files <- list(
        counts = file.path(outdir, "transcript_count.csv.gz"),
        isoform_annotated = isoform_annotated,
        outdir = outdir,
        transcript_assembly = file.path(outdir, "transcript_assembly.fa"),
        align_bam = file.path(outdir, "align2genome.bam"),
        realign2transcript = file.path(outdir, "realign2transcript.bam"),
        tss_tes = file.path(outdir, "tss_tes.bedgraph")
    )
    if (!missing("annotation") && !is.null(annotation)) {
        out_files[["annotation"]] <- annotation
        load_genome_anno <- rtracklayer::import(annotation, feature.type = c("exon", "utr"))
        return(generate_bulk_summarized(out_files, load_genome_anno = load_genome_anno))
    } else {
        return(generate_bulk_summarized(out_files))
    }
}
