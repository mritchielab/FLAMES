#' Pipeline for Multi-sample Single Cell Data
#'
#' @md
#'
#' @description
#' Semi-supervised isoform detection and annotation for long read data.
#' This variant is for multi-sample single cell data. By default, this pipeline demultiplexes input
#' fastq data (\code{match_cell_barcode = TRUE}). Specific parameters relating to
#' analysis can be changed either through function arguments, or through a
#' configuration JSON file.
#'
#' @details
#' By default FLAMES use minimap2 for read alignment. After the genome alignment step (\code{do_genome_align}), FLAMES summarizes the alignment for each read in every sample by grouping reads
#' with similar splice junctions to get a raw isoform annotation (\code{do_isoform_id}). The raw isoform
#' annotation is compared against the reference annotation to correct potential splice site
#' and transcript start/end errors. Transcripts that have similar splice junctions
#' and transcript start/end to the reference transcript are merged with the
#' reference. This process will also collapse isoforms that are likely to be truncated
#' transcripts. If \code{isoform_id_bambu} is set to \code{TRUE}, \code{bambu::bambu} will be used to generate the updated annotations (Not implemented for multi-sample yet).
#' Next is the read realignment step (\code{do_read_realign}), where the sequence of each transcript from the update annotation is extracted, and
#' the reads are realigned to this updated \code{transcript_assembly.fa} by minimap2. The
#' transcripts with only a few full-length aligned reads are discarded (Not implemented for multi-sample yet).
#' The reads are assigned to transcripts based on both alignment score, fractions of
#' reads aligned and transcript coverage. Reads that cannot be uniquely assigned to
#' transcripts or have low transcript coverage are discarded. The UMI transcript
#' count matrix is generated by collapsing the reads with the same UMI in a similar
#' way to what is done for short-read scRNA-seq data, but allowing for an edit distance
#' of up to 2 by default. Most of the parameters, such as the minimal distance to splice site and minimal percentage of transcript coverage
#' can be modified by the JSON configuration file (\code{config_file}).
#'
#' @param fastqs A vector containing the paths to each fastq files. If \code{in_bams} is not provided, this argument can also
#' be provided as the path to the folder containing the fastq files. Each fastq file will be treated as a sample.
#' @param in_bams Optional vector containing file paths the  bam files to use instead of fastq file (skips initial alignment step).
#' The order of the bam files need to mach the order in \code{fastqs}.
#' @inheritParams sc_long_pipeline
#' @return \code{sc_long_pipeline} returns a SingleCellExperiment object, containing a count
#' matrix as an assay, gene annotations under metadata, as well as a list of the other
#' output files generated by the pipeline. The pipeline also outputs a number of output
#' files into the given \code{outdir} directory. These output files generated by the pipeline are:
#' \itemize{
#'  \item{transcript_count.csv.gz}{ - a transcript count matrix (also contained in the SingleCellExperiment)}
#'  \item{isoform_annotated.filtered.gff3}{ - isoforms in gff3 format (also contained in the SingleCellExperiment)}
#'  \item{transcript_assembly.fa}{ - transcript sequence from the isoforms}
#'  \item{align2genome.bam}{ - sorted BAM file with reads aligned to genome}
#'  \item{realign2transcript.bam}{ - sorted realigned BAM file using the transcript_assembly.fa as reference}
#'  \item{tss_tes.bedgraph}{ - TSS TES enrichment for all reads (for QC)}
#' }
#'
#' @details The default parameters can be changed either through the function
#' arguments are through the configuration JSON file \code{config_file}. the \code{pipeline_parameters}
#' section specifies which steps are to be executed in the pipeline - by default, all
#' steps are executed. The \code{isoform_parameters} section affects isoform detection - key
#' parameters include:
#' \itemize{
#'  \item{\code{Min_sup_cnt}}{ which causes transcripts with less reads aligned than
#' it's value to be discarded}
#'  \item{\code{MAX_TS_DIST}}{ which merges transcripts with the same intron
#' chain and TSS/TES distace less than \code{MAX_TS_DIST}}
#'  \item{\code{strand_specific}}{ which specifies if reads are in the same strand as the mRNA (1),
#' or the reverse complemented (-1) or not strand specific (0), which results in
#' strand information being based on reference annotation.}
#' }
#'
#' @seealso
#' [bulk_long_pipeline()] for bulk long data,
#' [SingleCellExperiment()] for how data is outputted
#'
#' @importFrom dplyr group_by summarise_at slice_max filter
#' @importFrom magrittr "%>%"
#' @importFrom SingleCellExperiment SingleCellExperiment reducedDimNames logcounts
#' @importFrom SummarizedExperiment rowData colData rowData<- colData<- rowRanges rowRanges<-
#' @importFrom BiocGenerics cbind colnames rownames start end
#' @importFrom utils read.csv read.table file_test
#' @importFrom jsonlite fromJSON
#'
#' @example inst/examples/pipeline_example.R
#' @export
sc_long_multisample_pipeline <-
    function(annot,
             fastqs,
             in_bams = NULL,
             outdir,
             genome_fa,
             minimap2_dir = NULL,
             reference_csv,
             match_barcode = TRUE,
             config_file = NULL) {
        checked_args <- check_arguments(
            annot,
            fastqs,
            in_bams,
            outdir,
            genome_fa,
            minimap2_dir,
            config_file
        )

        config <- checked_args$config

        # check fastqs
        if (length(fastqs) == 1) {
            if (file_test("-f", fastqs)) {
                stop("Only one fastq file provided, did you meant to used the single-sample pipeline (FLAMES::sc_long_pipeline) ?")
            }

            fastqs <- file.path(fastqs, list.files(fastqs))
            fastqs <- fastqs[endsWith(fastqs, ".fq") | endsWith(fastqs, ".fastq")]
            if (length(fastqs) == 0) {
                stop("No .fq or .fastq files found")
            }
            cat("Fastq files found:\n")
            cat(paste0(fastqs, sep = "\n"))
            if (match_barcode) {
                stop("If \"match_barcode\" set to TRUE, argument \"fastqs\" must be a list of fastq files, with the same order in \"reference_csv\"")
            }
        } else if (any(!file.exists(fastqs))) {
            stop("Please make sure all fastq files exist.")
        }

        samples <- gsub(".fq$", "", gsub(".fastq$", "", basename(fastqs)))

        if (match_barcode) {
            if (!all(file.exists(reference_csv)) || length(reference_csv) != length(fastqs)) {
                stop("A reference_csv must exists for every fastq file.")
            }

            # speed up with lapply?
            infqs <- file.path(outdir, paste(samples, "matched_reads.fastq.gz", sep = "_"))
            bc_stats <- file.path(outdir, paste(samples, "matched_barcode_stat", sep = "_"))
            for (i in length(fastqs)) {
                match_cell_barcode_cpp(
                    fastqs[i],
                    bc_stats[i],
                    infqs[i],
                    reference_csv[i],
                    config$isoform_parameters$MAX_DIST,
                    config$global_parameters$UMI_LEN
                )
            }
        } else {
            infqs <- fastqs
        } # requesting to not match barcodes implies `fastq` has already been run through the
        # function in a previous FLAMES call


        cat("Running FLAMES pipeline...\n")

        using_bam <- FALSE
        if (!is.null(in_bams)) {
            if (any(!file.exists(in_bams))) {
                stop("Please make sure all BAM file exist")
            }
            if (!all(file.exists(paste0(in_bams, ".bai")) | file.exists(paste0(in_bams, ".csi")))) {
                stop("Please make sure every BAM file is indexed")
            } else if (length(in_bams) != length(fastqs)) {
                stop("Please make sure a BAM file exists for every fastq file")
            }
            using_bam <- TRUE
            config$pipeline_parameters$do_genome_alignment <- FALSE
        }

        # setup of internal arguments which hold output files and intermediate files
        isoform_gff3 <- paste(outdir, "isoform_annotated.gff3", sep = "/")
        isoform_gff3_f <- paste(outdir, "isoform_annotated.filtered.gff3",
            sep =
                "/"
        )
        FSM_anno_out <- paste(outdir, "isoform_FSM_annotation.csv", sep = "/")
        raw_splice_isoform <- paste(outdir, "splice_raw.gff3", sep = "/")
        tss_tes_stat <- paste(outdir, "tss_tes.bedgraph", sep = "/")
        transcript_fa <- paste(outdir, "transcript_assembly.fa", sep = "/")
        transcript_fa_idx <- paste(outdir, "transcript_assembly.fa.fai",
            sep =
                "/"
        )
        tmp_bed <- paste(outdir, "tmp_splice_anno.bed12", sep = "/")


        tr_badcov_cnt_csvs <- paste(outdir, paste(samples, "transcript_count.bad_coverage.csv.gz", sep = "_"), sep = "/")
        tr_cnt_csvs <- paste(outdir, paste(samples, "transcript_count.csv.gz", sep = "_"), sep = "/")
        tmp_bams <- paste(outdir, paste(samples, "tmp_align.bam", sep = "_"), sep = "/")
        tmp_sams <- paste(outdir, paste(samples, "tmp_align.sam", sep = "_"), sep = "/")
        genome_bams <- paste(outdir, paste(samples, "align2genome.bam", sep = "_"), sep = "/")
        realign_bams <- paste(outdir, paste(samples, "realign2transcript.bam", sep = "_"), sep = "/")

        cat("#### Input parameters:\n")
        cat(jsonlite::toJSON(config, pretty = TRUE))
        cat("gene annotation:", annot, "\n")
        cat("genome fasta:", genome_fa, "\n")
        if (using_bam) {
            cat("input bam:", paste0(in_bams, sep = "\n"), "\n")
            genome_bams <- in_bams
        }
        cat("input fastqs:", paste0(fastqs, sep = "\n"), "\n")
        cat("output directory:", outdir, "\n")
        cat("directory containing minimap2:", minimap2_dir, "\n")

        # align reads to genome
        # if (!using_bam && config$pipeline_parameters$do_genome_alignment) {
        if (config$pipeline_parameters$do_genome_alignment) {
            cat("#### Aligning reads to genome using minimap2\n")
            for (i in 1:length(samples)) {
                cat(paste0(c("\tAligning sample ", samples[i], "...\n")))
                minimap2_align(
                    config,
                    genome_fa,
                    fastqs[i],
                    annot,
                    outdir,
                    minimap2_dir,
                    prefix = samples[i],
                    threads = NULL
                )
            }
        } else {
            cat("#### Skip aligning reads to genome\n")
        }

        # find isofroms
        isoform_objects <-
            find_isoform_multisample(
                annot,
                genome_bams,
                isoform_gff3,
                tss_tes_stat,
                genome_fa,
                transcript_fa,
                config$isoform_parameters$downsample_ratio,
                config,
                raw_splice_isoform
            )

        # realign to transcript
        # if (!using_bam && do_read_realign) {
        if (do_read_realign) {
            cat("#### Realign to transcript using minimap2\n")
            for (i in 1:length(samples)) {
                cat(paste0(c("\tRealigning sample ", samples[i], "...\n")))
                minimap2_realign(config, transcript_fa, fastqs[i], outdir, minimap2_dir, prefix = samples[i], threads = NULL)
            }
        } else {
            cat("#### Skip read realignment\n")
        }

        # quantification
        # TODO: implement filtering in R
        if (config$pipeline_parameters$do_transcript_quantification) {
            cat("#### Generating transcript count matrix\n")
            for (i in 1:length(samples)) {
                parse_realign <-
                    parse_realigned_bam(
                        realign_bams[i],
                        transcript_fa_idx,
                        # config$isoform_parameters$Min_sup_cnt,
                        1,
                        config$transcript_counting$min_tr_coverage,
                        config$transcript_counting$min_read_coverage
                    )
                tr_cnt <- wrt_tr_to_csv(
                    parse_realign$bc_tr_count_dict,
                    isoform_objects$transcript_dict_i,
                    tr_cnt_csvs[i],
                    isoform_objects$transcript_dict,
                    config$global_parameters$has_UMI
                )
                wrt_tr_to_csv(
                    parse_realign$bc_tr_badcov_count_dict,
                    isoform_objects$transcript_dict_i,
                    tr_badcov_cnt_csvs[i],
                    isoform_objects$transcript_dict,
                    config$global_parameters$has_UMI
                )
                # annotate_filter_gff(
                #    isoform_gff3,
                #    annot,
                #    isoform_gff3_f,
                #    FSM_anno_out,
                #    tr_cnt,
                #    config$isoform_parameters$Min_sup_cnt
                # )
            }
            annotate_full_splice_match_all_sample(FSM_anno_out, isoform_gff3, annot)
        } else {
            cat("#### Skip transcript quantification\n")
        }

        sce_list <- as.list(1:length(samples))
        names(sce_list) <- samples
        load_genome_anno <- rtracklayer::import(annot, feature.type = c("exon", "utr"))

        for (i in 1:length(samples)) {
            out_files <- list(
                "annot" = annot,
                "genome_fa" = genome_fa,
                "counts" = tr_cnt_csvs[i],
                "isoform_annotated" = isoform_gff3,
                "transcript_assembly" = transcript_fa,
                "config" = config_file,
                "align_bam" = genome_bams[i],
                "realign2transcript" = realign_bams[i],
                "tss_tes" = tss_tes_stat,
                "outdir" = outdir,
                "fsm_annotation" = FSM_anno_out
            )
            sce_list[[i]] <- generate_sc_singlecell(out_files, load_genome_anno = load_genome_anno)
        }

        return(sce_list)
    }
